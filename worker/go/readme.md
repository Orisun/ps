  训练方法  | 训练耗时/秒 | 验证集上的损失/10^{−4}
--- |   ---   |   ---  
  单机  |  276  |  2.81
  PS一台worker  |  280  |  2.93
  PS三台worker  |  120  |  2.63

单机完全可以完成训练，这个可作为baseline。若用PS集群存储参数W，仅使用一台worker进行迭代学习，训练耗时和损失函数与baseline持平，这说明虽然引入了网络IO开销，但由于是异步更新参数所以并没有花费更多的时间。当使用三台worker时每台只使用1/3的训练样本，所以理论上最短耗时为baseline的1/3，即90秒左右，而实际用了120秒，这是由于worker变多后PS集群的并行请求压力变大，worker在等待m轮之前的训练结果时要花费些时间。三台worker并行训练得到的损失函数依然可以与baseline持平。
